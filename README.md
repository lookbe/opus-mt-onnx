# Opus-MT ONNX Proof of Concept

This project is a **proof of concept** demonstrating how to run **Opus-MT machine translation models** using **ONNX Runtime**.

The implementation focuses on:
- Converting / loading Opus-MT models in ONNX format  
- Running inference using ONNX Runtime (CPU)  
- Showing a minimal working translation pipeline  

Most of the source code was **generated using Gemini AI**, then refined and integrated into this POC.

---

## ðŸš€ Features
- Loads encoder/decoder ONNX models from Opus-MT  
- Runs translation end-to-end  
- Lightweight, dependency-minimal setup  
- Easy to extend or integrate into other projects  

---

## ðŸ“¦ Requirements
- Python **or** C#/C++ depending on your chosen implementation  
- ONNX Runtime  
- Opus-MT models in ONNX format

---

## ðŸ“‚ Project Structure
